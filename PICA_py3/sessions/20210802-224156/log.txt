[DEBUG][2021-08-02 22:41:56]	TFboard files will be stored in sessions/20210802-224156/tfboard if applicable
[DEBUG][2021-08-02 22:41:56]	Provided arguments will be stored in sessions/20210802-224156/config.yaml
[INFO][2021-08-02 22:41:56]	Start to declare training variable
[INFO][2021-08-02 22:41:56]	Session will be ran in device: [cuda]
[INFO][2021-08-02 22:41:56]	Start to prepare data
[INFO][2021-08-02 22:41:56]	otrainset-------------
[INFO][2021-08-02 22:41:56]	5000
[INFO][2021-08-02 22:41:56]	ptrainset-------------
[INFO][2021-08-02 22:41:56]	5000
[INFO][2021-08-02 22:41:56]	testset-------------
[INFO][2021-08-02 22:41:56]	5000
[INFO][2021-08-02 22:41:56]	Start to build model
[DEBUG][2021-08-02 22:41:56]	Backbone [resnet34] is declared with cin [1] and cout [1000] [with] sobel
[DEBUG][2021-08-02 22:41:56]	Backbone will be created wit the following heads: [20, 5]
[DEBUG][2021-08-02 22:41:57]	Number of trainable parameters is [112]
[DEBUG][2021-08-02 22:41:57]	Number of frozen parameters is [2]
[DEBUG][2021-08-02 22:41:57]	Name of frozen parameters are: dict_keys(['sobel.0.weight', 'sobel.0.bias'])
[DEBUG][2021-08-02 22:41:57]	Going to use [Adam] optimizer for training with betas (0.9, 0.999), eps 0.000000, weight decay 0.000000 without amsgrad
[DEBUG][2021-08-02 22:41:57]	Going to use [fixed] learning policy for optimization with base learning rate [0.00001]
[INFO][2021-08-02 22:41:57]	Data parallel will be used for acceleration purpose
[INFO][2021-08-02 22:41:57]	Start to train at 0 epoch with learning rate 0.000010
[INFO][2021-08-02 22:41:57]	cfg.net_heads
[INFO][2021-08-02 22:41:57]	[20, 5]
[INFO][2021-08-02 22:41:57]	hidx, head
[INFO][2021-08-02 22:41:57]	0
[INFO][2021-08-02 22:41:57]	20
[INFO][2021-08-02 22:41:57]	hidx, head
[INFO][2021-08-02 22:41:57]	1
[INFO][2021-08-02 22:41:57]	5
[INFO][2021-08-02 22:41:57]	train_head-------------
[INFO][2021-08-02 22:41:57]	5000
[INFO][2021-08-02 22:41:57]	5000
[INFO][2021-08-02 22:44:19]	Batch: [ 0/79] Head: [0/2] Epoch: [  0/350] Progress: [0:02:22/3:07:30] Time: 142.407 (142.407) Data: 2.798 (2.798) Loss: 3.1821 (3.1821)
[INFO][2021-08-02 22:46:15]	Batch: [50/79] Head: [0/2] Epoch: [  0/350] Progress: [0:04:18/0:06:39] Time: 2.301 (5.063) Data: 0.001 (0.056) Loss: 2.8589 (2.9435)
[INFO][2021-08-02 22:48:27]	train_head-------------
[INFO][2021-08-02 22:48:27]	5000
[INFO][2021-08-02 22:48:27]	5000
[INFO][2021-08-02 22:48:33]	Batch: [ 0/79] Head: [1/2] Epoch: [  0/350] Progress: [0:00:05/0:06:54] Time: 5.247 (5.247) Data: 2.846 (2.846) Loss: 1.7732 (1.7732)
[INFO][2021-08-02 22:50:28]	Batch: [50/79] Head: [1/2] Epoch: [  0/350] Progress: [0:02:00/0:03:07] Time: 2.299 (2.370) Data: 0.001 (0.057) Loss: 1.3504 (1.3827)
[INFO][2021-08-02 22:51:31]	Start to evaluate after 0 epoch of training
[INFO][2021-08-02 22:51:31]	len(loader.dataset)
[INFO][2021-08-02 22:51:31]	5000
